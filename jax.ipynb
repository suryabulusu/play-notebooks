{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jax.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPR0Et+0B9wK8v3sgwP8vsd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qk-h41dYsR6o","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596803364748,"user_tz":-330,"elapsed":3046,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["import random\n","import itertools\n","\n","import jax\n","import jax.numpy as np # always..\n","import numpy as onp # original numpy"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6wvk4TKtDNi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596803370809,"user_tz":-330,"elapsed":1159,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","def net(params, x):\n","  w1, b1, w2, b2 = params\n","  hidden = np.tanh(np.dot(w1, x) + b1)\n","  return sigmoid(np.dot(w2, hidden) + b2)\n","\n","def loss(params, x, y):\n","  out = net(params, x)\n","  cross_entropy = -y * np.log(out) - (1 - y) * np.log(1 - out)\n","  return cross_entropy\n","\n","def test_all_inputs(inputs, params):\n","  preds = [int(net(params, x) > 0.5) for x in inputs]\n","  return (preds == [onp.bitwise_xor(*x) for x in inputs]) # note onp, note *x for unzip"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqekeWMluwle","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596803382067,"user_tz":-330,"elapsed":1063,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["# jax provides better reproducibility via random num gen\n","# however, we prefer onp here... why... colin why\n","\n","def initial_params():\n","  return [\n","          onp.random.randn(3, 2), # w1\n","          onp.random.randn(3), # b1\n","          onp.random.randn(3), # w2\n","          onp.random.randn() # b2\n","  ]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFU-ob1cvryZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1596803400337,"user_tz":-330,"elapsed":7193,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"4ad9b3a0-f8a6-474a-acd0-cb45ec91ec69"},"source":["loss_grad = jax.grad(loss)\n","\n","eta = 1\n","\n","inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","\n","params = initial_params()\n","\n","for n in itertools.count():\n","  x = inputs[onp.random.choice(inputs.shape[0])]\n","  y = onp.bitwise_xor(*x)\n","\n","  # by default, the gradient is taken with the first argument of \"loss\"\n","  # that is, params\n","  grads = loss_grad(params, x, y)\n","\n","  params = [param - eta * grad for param, grad in zip(params, grads)]\n","\n","  if not n % 100:\n","    print(\"Iteration\", n)\n","    if test_all_inputs(inputs, params): break"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Iteration 0\n","Iteration 100\n","Iteration 200\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bsd3VkMexMjj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1596803404909,"user_tz":-330,"elapsed":1099,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"4a99372d-655c-4d5b-bdd4-36c7dd6ae51f"},"source":["for param in params:\n","  print(param)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[[-2.915513  -3.1900535]\n"," [ 2.7019804  1.3214543]\n"," [-2.9132302 -3.1299062]]\n","[ 0.77140146 -2.70173     0.73939276]\n","[-1.5628929 -1.8294228 -1.5880487]\n","-2.5038054\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"92U47Rvkxb09","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596803420432,"user_tz":-330,"elapsed":6472,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"3ea3666c-3e3b-44a0-c77c-6be9bd4db887"},"source":["# when i JIT compile my loss function... I achieve nice speedup\n","# this is for XLA stuff, and GPU / TPU\n","\n","%timeit loss_grad(params, x, y) # x, y from final iteration :P"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 12.5 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NUR-pr7zyj0a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596803425096,"user_tz":-330,"elapsed":3160,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"10a6bd0c-68c8-414b-b08c-ae69b7612e52"},"source":["# now, i'll JIT compile it\n","loss_grad = jax.jit(jax.grad(loss))\n","\n","# call loss_grad once to compile\n","loss_grad(params, x, y)\n","\n","# now time it. this is the right way, coz in sgd too, we'd be calling\n","# loss_grad lots of times after compilation\n","%timeit loss_grad(params, x, y)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["1000 loops, best of 3: 433 Âµs per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0JXvHUNRynKn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596803483964,"user_tz":-330,"elapsed":5055,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"d4bf5b73-ea58-4ff5-f5cf-c6be010a4230"},"source":["# vmap => easily convert SGD into minibatch GD\n","\n","loss_grad = jax.jit(jax.vmap(jax.grad(loss), in_axes = (None, 0, 0), out_axes = 0))\n","\n","params = initial_params()\n","\n","batch_size = 100\n","\n","for n in itertools.count():\n","  x = inputs[onp.random.choice(inputs.shape[0], size = batch_size)]\n","  y = onp.bitwise_xor(x[:, 0], x[:, 1])\n","  grads = loss_grad(params, x, y)\n","\n","  params = [param - eta * np.mean(grad, axis = 0) for param, grad in zip(params, grads)]\n","\n","  # if n > 500: break\n","\n","  if not n % 100:\n","    print(n)\n","    if test_all_inputs(inputs, params): break"],"execution_count":8,"outputs":[{"output_type":"stream","text":["0\n","100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5DBkY_985avH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1596803491165,"user_tz":-330,"elapsed":1271,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"1e221f20-599f-4044-e7fe-cf2bdd392554"},"source":["for param in params:\n","  print(param)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[ 1.6345334 -2.2520266]\n"," [-1.8182846 -1.1511141]\n"," [ 1.7510666  2.6979718]]\n","[ 1.9308393   0.63822705 -3.4900067 ]\n","[-2.5126188 -2.361304  -2.6519485]\n","-0.49163997\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D2AR21j8huQH","colab_type":"text"},"source":["# More JAX basics"]},{"cell_type":"code","metadata":{"id":"3IzqY4A7hzYD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1596803496281,"user_tz":-330,"elapsed":2133,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"74414abe-cf9b-436e-96eb-ca95701e5435"},"source":["x = onp.random.normal(size=(3000,3000))\n","%timeit np.dot(x, x.T)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["The slowest run took 7.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n","1 loop, best of 3: 58.4 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mPNFLUI4hZHe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596803514382,"user_tz":-330,"elapsed":4681,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"4444bb5a-4cb7-473f-a0d0-0f7d7787cb8b"},"source":["%timeit onp.dot(x, x.T)\n","# notice the speedup <3"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1 loop, best of 3: 786 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSh3YViOhuqC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596803534710,"user_tz":-330,"elapsed":4410,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"f5d4a5f7-f08d-4b98-d6b7-bfe4e95abb35"},"source":["%timeit np.dot(x, x.T).block_until_ready()\n","# a bit longer... coz jax implemented asynchronous dispatch before..\n","# that is, it gives us partial result of 3000 * 3000 without completing it entirely\n","# this is useful for accelerators which don't need entire output immediately  "],"execution_count":12,"outputs":[{"output_type":"stream","text":["10 loops, best of 3: 80.1 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gMghm-utiSfR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596803578154,"user_tz":-330,"elapsed":10011,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"75161169-b99b-4333-da43-efd45e935264"},"source":["import jax.random as jrandom\n","\n","key = jrandom.PRNGKey(0)\n","y = jrandom.normal(key=key, shape=(3000, 3000))\n","%timeit np.dot(y, y.T)\n","\n","# this is much faster, coz no need to transfer numpy array from cpu to gpu \n","# unlike before...\n","# the array is directly created in device (GPU) coz jax wala random "],"execution_count":13,"outputs":[{"output_type":"stream","text":["100 loops, best of 3: 20.6 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0l9KZ_q1i6Mg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1588489619455,"user_tz":-330,"elapsed":2353,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"b7c3235d-ceb4-412d-b338-ce41b672f774"},"source":["# computing Jacobian using forward and reverse mode\n","# y = C(B(A(x))) => dy/dx = dy/dc * dc/db * db/da * da/dx\n","# forward => dy/dx = (dy/dc * (dc/db * (db/da * da/dx)))\n","# reverse => dy/dx = (((dy/dc * dc/db) * db/da) * da/dx)\n","\n","# which one's better? mostly reverse.. coz x \\in R^n, y \\in R for most opt probs\n","\n","from jax import jacfwd, jacrev\n","\n","# isolate w_1\n","w_1, b_1, w_2, b_2 = params\n","f = lambda w: loss([w, b_1, w_2, b_2], np.array([0, 1]), 1)\n","\n","J = jacfwd(f)(w_1)\n","print(J.shape)\n","print(J)\n","\n","J = jacrev(f)(w_1)\n","print(J.shape)\n","print(J)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3, 2)\n","[[0.         0.00120079]\n"," [0.         0.00013758]\n"," [0.         0.07751656]]\n","(3, 2)\n","[[0.         0.00120079]\n"," [0.         0.00013758]\n"," [0.         0.07751656]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CvOG9427H0xd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1588489637245,"user_tz":-330,"elapsed":1935,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"08bb9d02-4e60-49c3-dd17-20c2022874ef"},"source":["# much more succintly\n","J_list = jacfwd(loss)(params, np.array([0,1]), 1)\n","print(J_list)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[DeviceArray([[0.        , 0.00120079],\n","             [0.        , 0.00013758],\n","             [0.        , 0.07751656]], dtype=float32), DeviceArray([0.00120079, 0.00013758, 0.07751656], dtype=float32), DeviceArray([ 0.06271198, -0.06307167,  0.05167241], dtype=float32), DeviceArray(-0.06309009, dtype=float32)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Vf0YIFb5H2GI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588489729114,"user_tz":-330,"elapsed":1238,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}},"outputId":"68197838-6cf6-4f51-fa27-d6997811bf04"},"source":["# jacobian vector product jvp\n","\n","from jax import jvp\n","\n","# note that v is a vector in w_1 \\in R^(3*2) space\n","v = onp.random.normal(size = w_1.shape)\n","loss_val, jvp_val = jvp(f, (w_1,), (v,))\n","\n","print(loss_val, jvp_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.06516814 0.023711631\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lKXNoZa7P-KD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1579160977270,"user_tz":-330,"elapsed":2101,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDf51hMw-AyQyx3OWnVOBTZgPXNkCR_ushLds1RiA=s64","userId":"04825268471411861520"}},"outputId":"08f3a571-bb01-409e-8747-fc7061548c0d"},"source":["# vector jacobian product vjp\n","\n","loss_val, vjp_val = jax.vjp(f, w_1)\n","\n","u = onp.random.normal(size = loss_val.shape)\n","\n","v = vjp_val(u)\n","print(v) # which will be of shape w_1, ie, (3,2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(DeviceArray([[ 0.        ,  0.03020284],\n","             [-0.        , -0.00504099],\n","             [-0.        , -0.01350596]], dtype=float32),)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oPIR4clKRNr9","colab_type":"code","colab":{}},"source":["# jit gotcha\n","# the point of compiling with @jit is.. we don't want to compile again..\n","# we want to ensure that the inputs to the fn remain same later on too..\n","# as in, say inp = [2, 3, 4] .. we expect that other inps are also of [a, b, c] form \n","\n","# when u encounter control flow type statements on inp in fn, @jit becomes mad"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9b3cEGIGm6V","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}