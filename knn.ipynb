{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"knn.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1U4qhzJZkss25myqairjJr2gwyqEWTxFg","authorship_tag":"ABX9TyNc868jazAwhLOGaHr3ddem"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4PmkErx4L7oa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8a0b5632-5c8d-46f4-f0bb-ad20e877e42d","executionInfo":{"status":"ok","timestamp":1590433170305,"user_tz":-330,"elapsed":1534,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["cd drive/My\\ Drive/assignment1 "],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/assignment1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bDreWLDMMQeN","colab_type":"code","colab":{}},"source":["# Run some setup code for this notebook.\n","\n","import random\n","import numpy as np\n","import PIL\n","from cs231n.data_utils import load_CIFAR10\n","import matplotlib.pyplot as plt\n","\n","# This is a bit of magic to make matplotlib figures appear inline in the notebook\n","# rather than in a new window.\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# Some more magic so that the notebook will reload external python modules;\n","# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pCs3T1FQNW07","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"a176412c-0146-4fd3-de16-8f1fe07eb805","executionInfo":{"status":"ok","timestamp":1590433285721,"user_tz":-330,"elapsed":10671,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["!sh cs231n/datasets/get_datasets.sh"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2020-05-25 19:01:16--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  47.2MB/s    in 3.8s    \n","\n","2020-05-25 19:01:20 (43.1 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n","cifar-10-batches-py/\n","cifar-10-batches-py/data_batch_4\n","cifar-10-batches-py/readme.html\n","cifar-10-batches-py/test_batch\n","cifar-10-batches-py/data_batch_3\n","cifar-10-batches-py/batches.meta\n","cifar-10-batches-py/data_batch_2\n","cifar-10-batches-py/data_batch_5\n","cifar-10-batches-py/data_batch_1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bz-HILWSMql6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"ec21f319-0914-4b58-be91-1a353c8cff04","executionInfo":{"status":"ok","timestamp":1590439216470,"user_tz":-330,"elapsed":5414,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["# Load the raw CIFAR-10 data.\n","cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n","\n","# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n","try:\n","   del X_train, y_train\n","   del X_test, y_test\n","   print('Clear previously loaded data.')\n","except:\n","   pass\n","\n","X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","\n","# As a sanity check, we print out the size of the training and test data.\n","print('Training data shape: ', X_train.shape)\n","print('Training labels shape: ', y_train.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["Clear previously loaded data.\n","Training data shape:  (50000, 32, 32, 3)\n","Training labels shape:  (50000,)\n","Test data shape:  (10000, 32, 32, 3)\n","Test labels shape:  (10000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7VVRxw7wkDmH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"49fc7613-58c3-445b-e245-a7c463fccbd7","executionInfo":{"status":"ok","timestamp":1590439219875,"user_tz":-330,"elapsed":1321,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["# Split the data into train, val, and test sets. In addition we will\n","# create a small development set as a subset of the training data;\n","# we can use this for development so our code runs faster.\n","num_training = 49000\n","num_validation = 1000\n","num_test = 1000\n","num_dev = 500\n","\n","# Our validation set will be num_validation points from the original\n","# training set.\n","mask = range(num_training, num_training + num_validation)\n","X_val = X_train[mask]\n","y_val = y_train[mask]\n","\n","# Our training set will be the first num_train points from the original\n","# training set.\n","mask = range(num_training)\n","X_train = X_train[mask]\n","y_train = y_train[mask]\n","\n","# We will also make a development set, which is a small subset of\n","# the training set.\n","mask = np.random.choice(num_training, num_dev, replace=False)\n","X_dev = X_train[mask]\n","y_dev = y_train[mask]\n","\n","# We use the first num_test points of the original test set as our\n","# test set.\n","mask = range(num_test)\n","X_test = X_test[mask]\n","y_test = y_test[mask]\n","\n","print('Train data shape: ', X_train.shape)\n","print('Train labels shape: ', y_train.shape)\n","print('Validation data shape: ', X_val.shape)\n","print('Validation labels shape: ', y_val.shape)\n","print('Test data shape: ', X_test.shape)\n","print('Test labels shape: ', y_test.shape)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Train data shape:  (49000, 32, 32, 3)\n","Train labels shape:  (49000,)\n","Validation data shape:  (1000, 32, 32, 3)\n","Validation labels shape:  (1000,)\n","Test data shape:  (1000, 32, 32, 3)\n","Test labels shape:  (1000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m8UBTkopkPHd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"6a076f34-475e-4544-a36e-789427f0636a","executionInfo":{"status":"ok","timestamp":1590439246909,"user_tz":-330,"elapsed":1038,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["# Preprocessing: reshape the image data into rows\n","X_train = np.reshape(X_train, (X_train.shape[0], -1))\n","X_val = np.reshape(X_val, (X_val.shape[0], -1))\n","X_test = np.reshape(X_test, (X_test.shape[0], -1))\n","X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n","\n","# As a sanity check, print out the shapes of the data\n","print('Training data shape: ', X_train.shape)\n","print('Validation data shape: ', X_val.shape)\n","print('Test data shape: ', X_test.shape)\n","print('dev data shape: ', X_dev.shape)"],"execution_count":68,"outputs":[{"output_type":"stream","text":["Training data shape:  (49000, 3072)\n","Validation data shape:  (1000, 3072)\n","Test data shape:  (1000, 3072)\n","dev data shape:  (500, 3072)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AIS8ZgmqkQe_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":317},"outputId":"6cc7cf11-c114-4bb5-bf1f-ba3afbd30573","executionInfo":{"status":"ok","timestamp":1590439292188,"user_tz":-330,"elapsed":2213,"user":{"displayName":"Surya Teja","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh9OE9xZOmgCsYbSDcyWWLmdv2woZyYW7QocaVC0g=s64","userId":"04825268471411861520"}}},"source":["# Preprocessing: subtract the mean image\n","# first: compute the image mean based on the training data\n","mean_image = np.mean(X_train, axis=0)\n","print(mean_image[:10]) # print a few of the elements\n","plt.figure(figsize=(4,4))\n","plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # visualize the mean image\n","plt.show()\n","\n","# second: subtract the mean image from train and test data\n","X_train -= mean_image\n","X_val -= mean_image\n","X_test -= mean_image\n","X_dev -= mean_image\n","\n","# third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n","# only has to worry about optimizing a single weight matrix W.\n","X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n","X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n","X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n","X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n","\n","print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)"],"execution_count":69,"outputs":[{"output_type":"stream","text":["[130.64189796 135.98173469 132.47391837 130.05569388 135.34804082\n"," 131.75402041 130.96055102 136.14328571 132.47636735 131.48467347]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["(49000, 3073) (1000, 3073) (1000, 3073) (500, 3073)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HSE5CpAiapmk","colab_type":"code","colab":{}},"source":["num_folds = 5\n","k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n","\n","X_train_folds = []\n","y_train_folds = []\n","################################################################################\n","# TODO:                                                                        #\n","# Split up the training data into folds. After splitting, X_train_folds and    #\n","# y_train_folds should each be lists of length num_folds, where                #\n","# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n","# Hint: Look up the numpy array_split function.                                #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","X_train_folds = np.array_split(X_train, 5)\n","y_train_folds = np.array_split(y_train, 5)\n","\n","X_train_folds = np.array(X_train_folds)\n","y_train_folds = np.array(y_train_folds)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# A dictionary holding the accuracies for different values of k that we find\n","# when running cross-validation. After running cross-validation,\n","# k_to_accuracies[k] should be a list of length num_folds giving the different\n","# accuracy values that we found when using that value of k.\n","k_to_accuracies = {}\n","\n","\n","################################################################################\n","# TODO:                                                                        #\n","# Perform k-fold cross validation to find the best value of k. For each        #\n","# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n","# where in each case you use all but one of the folds as training data and the #\n","# last fold as a validation set. Store the accuracies for all fold and all     #\n","# values of k in the k_to_accuracies dictionary.                               #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","num_folds_range = np.array(list(range(num_folds)))\n","feat_shape = X_train[0].shape[0]\n","\n","for k in k_choices:\n","  accu = []\n","  for fold in num_folds_range:\n","    train_idxs = np.setdiff1d(num_folds_range, fold)\n","    # print(train_idxs)\n","    curr_X_train, curr_y_train = X_train_folds[train_idxs], y_train_folds[train_idxs]\n","    classifier.train(np.reshape(curr_X_train, (-1, feat_shape)), np.reshape(curr_y_train, -1))\n","    dists = classifier.compute_distances_no_loops(X_train_folds[fold])\n","    y_fold_preds = classifier.predict_labels(dists, k)\n","    num_correct = np.sum(y_fold_preds == y_train_folds[fold])\n","    accu.append(float(num_correct) / np.shape(y_fold_preds)[0])\n","  k_to_accuracies[k] = accu\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Print out the computed accuracies\n","for k in sorted(k_to_accuracies):\n","    for accuracy in k_to_accuracies[k]:\n","        print('k = %d, accuracy = %f' % (k, accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvXc-jL7jDI9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}